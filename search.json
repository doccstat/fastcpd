[{"path":"https://fastcpd.xingchi.li/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007 Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://fastcpd.xingchi.li/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://fastcpd.xingchi.li/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://fastcpd.xingchi.li/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://fastcpd.xingchi.li/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://fastcpd.xingchi.li/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://fastcpd.xingchi.li/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://fastcpd.xingchi.li/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://fastcpd.xingchi.li/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://fastcpd.xingchi.li/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://fastcpd.xingchi.li/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://fastcpd.xingchi.li/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://fastcpd.xingchi.li/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://fastcpd.xingchi.li/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://fastcpd.xingchi.li/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://fastcpd.xingchi.li/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://fastcpd.xingchi.li/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://fastcpd.xingchi.li/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://fastcpd.xingchi.li/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://fastcpd.xingchi.li/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://fastcpd.xingchi.li/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"https://fastcpd.xingchi.li/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Xingchi Li. Author, maintainer, copyright holder. Xianyang Zhang. Author, copyright holder. Trisha Dawn. Author, copyright holder.","code":""},{"path":"https://fastcpd.xingchi.li/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Li X, Zhang X, Dawn T (2023). fastcpd: Fast Change Point Detection via Sequential Gradient Descent. R package version 0.8.3, https://CRAN.R-project.org/package=fastcpd. Zhang X, Dawn T (2023). “Sequential Gradient Descent Quasi-Newton's Method Change-Point Analysis.” Ruiz, Francisco, Dy, Jennifer, van de Meent, Jan-Willem (eds.), Proceedings 26th International Conference Artificial Intelligence Statistics, volume 206 series Proceedings Machine Learning Research, 1129–1143. https://proceedings.mlr.press/v206/zhang23b.html.","code":"@Manual{,   title = {fastcpd: Fast Change Point Detection via Sequential Gradient Descent},   author = {Xingchi Li and Xianyang Zhang and Trisha Dawn},   year = {2023},   note = {R package version 0.8.3},   url = {https://CRAN.R-project.org/package=fastcpd}, } @InProceedings{,   title = {Sequential Gradient Descent and Quasi-Newton's Method for Change-Point Analysis},   author = {Xianyang Zhang and Trisha Dawn},   year = {2023},   booktitle = {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},   volume = {206},   pages = {1129--1143},   editor = {{Ruiz} and {Francisco} and {Dy} and {Jennifer} and {van de Meent} and {Jan-Willem}},   series = {Proceedings of Machine Learning Research},   month = {25--27 Apr},   publisher = {PMLR},   pdf = {https://proceedings.mlr.press/v206/zhang23b/zhang23b.pdf},   url = {https://proceedings.mlr.press/v206/zhang23b.html},   abstract = {One common approach to detecting change-points is minimizing a cost function over possible numbers and locations of change-points. The framework includes several well-established procedures, such as the penalized likelihood and minimum description length. Such an approach requires finding the cost value repeatedly over different segments of the data set, which can be time-consuming when (i) the data sequence is long and (ii) obtaining the cost value involves solving a non-trivial optimization problem. This paper introduces a new sequential updating method (SE) to find the cost value effectively. The core idea is to update the cost value using the information from previous steps without re-optimizing the objective function. The new method is applied to change-point detection in generalized linear models and penalized regression. Numerical studies show that the new approach can be orders of magnitude faster than the Pruned Exact Linear Time (PELT) method without sacrificing estimation accuracy.}, }"},{"path":[]},{"path":"https://fastcpd.xingchi.li/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Fast Change Point Detection via Sequential Gradient Descent","text":"fastcpd (fast change point detection) fast implmentation change point detection methods R. fastcpd package designed find change points fast manner. easy install extensible kinds change point problems user specified cost function apart built-cost functions. learn behind algorithms: Sequential Gradient Descent Quasi-Newton’s Method Change-Point Analysis","code":""},{"path":"https://fastcpd.xingchi.li/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Fast Change Point Detection via Sequential Gradient Descent","text":"","code":"# Install from CRAN install.packages(\"fastcpd\") # Development version from r-universe with CRAN version as a fallback install.packages(   \"fastcpd\",   repos = c(\"https://doccstat.r-universe.dev\", \"https://cloud.r-project.org\") )  ## install.packages(\"pak\") pak::pak(\"doccstat/fastcpd\")  ## install.packages(\"devtools\") devtools::install_github(\"doccstat/fastcpd\") # conda-forge is a fork from CRAN and may not be up-to-date  # Use mamba mamba install r-fastcpd # Use conda conda install -c conda-forge r-fastcpd"},{"path":"https://fastcpd.xingchi.li/index.html","id":"faq","dir":"","previous_headings":"Installation","what":"FAQ","title":"Fast Change Point Detection via Sequential Gradient Descent","text":"fastcpd depends following packages: Rcpp, C++ source code compilation. RcppArmadillo, fast linear algebra. fastglm, fast generalized linear models. DescTools, Winsorizing Poisson data. glmnet, penalized regression. ggplot2, data visualization. ’re compiling source, can run following command see complete set system packages needed machine. package able install Mac Linux distribution without problems dependencies installed. However, encountered problems related gfortran, might RcppArmadillo installed previously. Try Mac OSX stackoverflow solution Linux stackover solution trouble installing RcppArmadillo.","code":"pak::pkg_sysreqs(\"doccstat/fastcpd\") #> ── Install scripts ───────────────────────────────────────────── Ubuntu 20.04 #> apt-get -y update #> apt-get -y install libcurl4-openssl-dev libssl-dev zlib1g-dev make #> #> ── Packages and their system dependencies ─────────────────────────────────── #> curl       – libcurl4-openssl-dev, libssl-dev #> data.table – zlib1g-dev #> fs         – make #> openssl    – libssl-dev"},{"path":[]},{"path":"https://fastcpd.xingchi.li/index.html","id":"examples","dir":"","previous_headings":"","what":"Examples","title":"Fast Change Point Detection via Sequential Gradient Descent","text":"Documentation","code":""},{"path":"https://fastcpd.xingchi.li/index.html","id":"linear-regression","dir":"","previous_headings":"Examples","what":"linear regression","title":"Fast Change Point Detection via Sequential Gradient Descent","text":"","code":"library(fastcpd) set.seed(1) p <- 3 x <- mvtnorm::rmvnorm(300, rep(0, p), diag(p)) theta_0 <- rbind(c(1, 1.2, -1), c(-1, 0, 0.5), c(0.5, -0.3, 0.2)) y <- c(   x[1:100, ] %*% theta_0[1, ] + rnorm(100, 0, 1),   x[101:200, ] %*% theta_0[2, ] + rnorm(100, 0, 1),   x[201:300, ] %*% theta_0[3, ] + rnorm(100, 0, 1) ) result <- fastcpd(   formula = y ~ . - 1,   data = data.frame(y = y, x = x),   family = \"gaussian\" ) plot(result) summary(result) #>  #> Call: #> fastcpd(formula = y ~ . - 1, data = data.frame(y = y, x = x),  #>     family = \"gaussian\") #>  #> Change points: #> 98 202  #>  #> Cost values: #> 53.44023 53.1441 45.04974  #>  #> Parameters: #>    segment 1   segment 2  segment 3 #> 1  0.9704022 -1.07884004  0.5925092 #> 2  1.1786074 -0.01757927 -0.5287126 #> 3 -0.9258587  0.63906143  0.1929411"},{"path":"https://fastcpd.xingchi.li/index.html","id":"linear-regression-with-one-dimensional-covariate","dir":"","previous_headings":"Examples","what":"linear regression with one-dimensional covariate","title":"Fast Change Point Detection via Sequential Gradient Descent","text":"","code":"library(fastcpd) set.seed(1) p <- 1 x <- mvtnorm::rmvnorm(300, rep(0, p), diag(p)) theta_0 <- matrix(c(1, -1, 0.5)) y <- c(   x[1:100, ] * theta_0[1, ] + rnorm(100, 0, 1),   x[101:200, ] * theta_0[2, ] + rnorm(100, 0, 1),   x[201:300, ] * theta_0[3, ] + rnorm(100, 0, 1) ) result <- fastcpd(   formula = y ~ . - 1,   data = data.frame(y = y, x = x),   family = \"gaussian\" ) plot(result) summary(result) #>  #> Call: #> fastcpd(formula = y ~ . - 1, data = data.frame(y = y, x = x),  #>     family = \"gaussian\") #>  #> Change points: #> 100 194  #>  #> Cost values: #> 48.71927 57.20738 63.15088  #>  #> Parameters: #>   segment 1  segment 2 segment 3 #> 1 0.9520606 -0.8054074 0.3692224"},{"path":"https://fastcpd.xingchi.li/index.html","id":"linear-regression-with-noise-variance-not-equal-to-1","dir":"","previous_headings":"Examples","what":"linear regression with noise variance not equal to 1","title":"Fast Change Point Detection via Sequential Gradient Descent","text":"","code":"library(fastcpd) set.seed(1) p <- 4 n <- 300 cp <- c(100, 200) x <- mvtnorm::rmvnorm(n, rep(0, p), diag(p)) theta_0 <- rbind(c(1, 3.2, -1, 0), c(-1, -0.5, 2.5, -2), c(0.8, -0.3, 1, 1)) y <- c(   x[1:cp[1], ] %*% theta_0[1, ] + rnorm(cp[1], 0, sd = 3),   x[(cp[1] + 1):cp[2], ] %*% theta_0[2, ] + rnorm(cp[2] - cp[1], 0, sd = 3),   x[(cp[2] + 1):n, ] %*% theta_0[3, ] + rnorm(n - cp[2], 0, sd = 3) )  result <- fastcpd(   data = data.frame(y = y, x = x),   family = \"gaussian\" ) summary(result) #>  #> Call: #> fastcpd(data = data.frame(y = y, x = x), family = \"gaussian\") #>  #> Change points: #> 100 201  #>  #> Cost values: #> 499.5254 328.5244 459.3819  #>  #> Parameters: #>    segment 1  segment 2  segment 3 #> 1  0.7054739 -0.5373328 0.23439463 #> 2  0.8005173 -0.8915565 0.87884516 #> 3  3.6097492 -0.5539604 0.03698789 #> 4 -1.3438206  2.2831450 1.01253653 #> 5  0.1352143 -2.0567371 1.28948015"},{"path":"https://fastcpd.xingchi.li/index.html","id":"logistic-regression","dir":"","previous_headings":"Examples","what":"logistic regression","title":"Fast Change Point Detection via Sequential Gradient Descent","text":"","code":"library(fastcpd) set.seed(1) x <- matrix(rnorm(1500, 0, 1), ncol = 5) theta <- rbind(rnorm(5, 0, 1), rnorm(5, 2, 1)) y <- c(   rbinom(125, 1, 1 / (1 + exp(-x[1:125, ] %*% theta[1, ]))),   rbinom(175, 1, 1 / (1 + exp(-x[126:300, ] %*% theta[2, ]))) ) result <- suppressWarnings(fastcpd(   formula = y ~ . - 1,   data = data.frame(y = y, x = x),   family = \"binomial\" )) summary(result) #>  #> Call: #> fastcpd(formula = y ~ . - 1, data = data.frame(y = y, x = x),  #>     family = \"binomial\") #>  #> Change points: #> 126  #>  #> Cost values: #> 56.90525 30.76875  #>  #> Parameters: #>    segment 1 segment 2 #> 1  0.7259293  1.878525 #> 2 -1.0294802  2.704376 #> 3  1.0576503  3.702310 #> 4 -0.8812767  2.258796 #> 5  0.2419351  2.524173"},{"path":"https://fastcpd.xingchi.li/index.html","id":"poisson-regression","dir":"","previous_headings":"Examples","what":"poisson regression","title":"Fast Change Point Detection via Sequential Gradient Descent","text":"","code":"library(fastcpd) set.seed(1) p <- 3 x <- mvtnorm::rmvnorm(1500, rep(0, p), diag(p)) delta <- rnorm(p) theta_0 <- c(1, 1.2, -1) y <- c(   rpois(300, exp(x[1:300, ] %*% theta_0)),   rpois(400, exp(x[301:700, ] %*% (theta_0 + delta))),   rpois(300, exp(x[701:1000, ] %*% theta_0)),   rpois(100, exp(x[1001:1100, ] %*% (theta_0 - delta))),   rpois(200, exp(x[1101:1300, ] %*% theta_0)),   rpois(200, exp(x[1301:1500, ] %*% (theta_0 + delta))) ) result <- fastcpd(   formula = y ~ . - 1,   data = data.frame(y = y, x = x),   beta = (p + 1) * log(1500) / 2,   k = function(x) 0,   family = \"poisson\",   epsilon = 1e-5 ) summary(result) #>  #> Call: #> fastcpd(formula = y ~ . - 1, data = data.frame(y = y, x = x),  #>     beta = (p + 1) * log(1500)/2, k = function(x) 0, family = \"poisson\",  #>     epsilon = 1e-05) #>  #> Change points: #> 329 728 1021 1107 1325  #>  #> Cost values: #> 14425.87 13971.23 697.2187 107.5353 380.7153 51.93594  #>  #> Parameters: #>     segment 1  segment 2  segment 3  segment 4 segment 5  segment 6 #> 1  2.60927673  1.9255183  0.7405125 -0.3965022  1.117753  2.5479308 #> 2  0.02398457  0.1068924  1.4721444  1.8677797  1.019035  0.4947115 #> 3 -1.34361104 -2.7353603 -0.8906937  0.4651667 -1.178933 -2.5038966 result_two_epochs <- fastcpd(   formula = y ~ . - 1,   data = data.frame(y = y, x = x),   beta = (p + 1) * log(1500) / 2,   k = function(x) 1,   family = \"poisson\",   epsilon = 1e-4 ) summary(result_two_epochs) #>  #> Call: #> fastcpd(formula = y ~ . - 1, data = data.frame(y = y, x = x),  #>     beta = (p + 1) * log(1500)/2, k = function(x) 1, family = \"poisson\",  #>     epsilon = 1e-04) #>  #> Change points: #> 328 716 1020 1102 1323  #>  #> Cost values: #> 14417.14 2976.961 717.4614 31.48528 296.6285 53.94423  #>  #> Parameters: #>     segment 1  segment 2  segment 3  segment 4 segment 5  segment 6 #> 1  2.60955822  2.4484869  0.7832980 -0.5008107  1.105317  2.5479958 #> 2  0.02371536  0.4084502  1.4456715  1.9282798  1.057743  0.4951862 #> 3 -1.34277129 -2.5426556 -0.8989812  0.5197285 -1.128259 -2.5035143"},{"path":"https://fastcpd.xingchi.li/index.html","id":"penalized-linear-regression","dir":"","previous_headings":"Examples","what":"penalized linear regression","title":"Fast Change Point Detection via Sequential Gradient Descent","text":"","code":"library(fastcpd) set.seed(1) n <- 1500 p_true <- 6 p <- 50 x <- mvtnorm::rmvnorm(1500, rep(0, p), diag(p)) theta_0 <- rbind(   runif(p_true, -5, -2),   runif(p_true, -3, 3),   runif(p_true, 2, 5),   runif(p_true, -5, 5) ) theta_0 <- cbind(theta_0, matrix(0, ncol = p - p_true, nrow = 4)) y <- c(   x[1:300, ] %*% theta_0[1, ] + rnorm(300, 0, 1),   x[301:700, ] %*% theta_0[2, ] + rnorm(400, 0, 1),   x[701:1000, ] %*% theta_0[3, ] + rnorm(300, 0, 1),   x[1001:1500, ] %*% theta_0[4, ] + rnorm(500, 0, 1) ) result <- fastcpd(   formula = y ~ . - 1,   data = data.frame(y = y, x = x),   family = \"lasso\" ) plot(result) summary(result) #>  #> Call: #> fastcpd(formula = y ~ . - 1, data = data.frame(y = y, x = x),  #>     family = \"lasso\") #>  #> Change points: #> 300 700 1000  #>  #> Cost values: #> 202.6103 254.6904 183.5909 302.4998  #>  #> Parameters: #> 50 x 4 sparse Matrix of class \"dgCMatrix\" #>       segment 1  segment 2 segment 3  segment 4 #>  [1,] -2.892654  0.3344843  4.046784  .         #>  [2,] -2.831352 -0.3687367  3.907948  3.1109044 #>  [3,] -2.817023 -0.1990682  2.574074  2.7732194 #>  [4,] -1.926208  0.4740742  3.322680 -0.5366242 #>  [5,] -3.066517 -0.4659526  2.092768 -3.3781507 #>  [6,] -1.842233  0.4168482  4.798087  .         #>  [7,]  .         .          .         .         #>  [8,]  .         .          .         .         #>  [9,]  .         .          .         .         #> [10,]  .         .          .         .         #> [11,]  .         .          .         .         #> [12,]  .         .          .         .         #> [13,]  .         .          .         .         #> [14,]  .         .          .         .         #> [15,]  .         .          .         .         #> [16,]  .         .          .         .         #> [17,]  .         .          .         .         #> [18,]  .         .          .         .         #> [19,]  .         .          .         .         #> [20,]  .         .          .         .         #> [21,]  .         .          .         .         #> [22,]  .         .          .         .         #> [23,]  .         .          .         .         #> [24,]  .         .          .         .         #> [25,]  .         .          .         .         #> [26,]  .         .          .         .         #> [27,]  .         .          .         .         #> [28,]  .         .          .         .         #> [29,]  .         .          .         .         #> [30,]  .         .          .         .         #> [31,]  .         .          .         .         #> [32,]  .         .          .         .         #> [33,]  .         .          .         .         #> [34,]  .         .          .         .         #> [35,]  .         .          .         .         #> [36,]  .         .          .         .         #> [37,]  .         .          .         .         #> [38,]  .         .          .         .         #> [39,]  .         .          .         .         #> [40,]  .         .          .         .         #> [41,]  .         .          .         .         #> [42,]  .         .          .         .         #> [43,]  .         .          .         .         #> [44,]  .         .          .         .         #> [45,]  .         .          .         .         #> [46,]  .         .          .         .         #> [47,]  .         .          .         .         #> [48,]  .         .          .         .         #> [49,]  .         .          .         .         #> [50,]  .         .          .         ."},{"path":"https://fastcpd.xingchi.li/index.html","id":"ar1-model","dir":"","previous_headings":"Examples","what":"ar(1) model","title":"Fast Change Point Detection via Sequential Gradient Descent","text":"","code":"library(fastcpd) set.seed(1) n <- 1000 p <- 1 x <- rep(0, n + 1) for (i in 1:600) {   x[i + 1] <- 0.6 * x[i] + rnorm(1) } for (i in 601:1000) {   x[i + 1] <- 0.3 * x[i] + rnorm(1) } result <- fastcpd(   formula = ~ . - 1,   data = data.frame(x = x),   p = 1,   family = \"ar\" ) summary(result) #>  #> Call: #> fastcpd(formula = ~. - 1, data = data.frame(x = x), family = \"ar\",  #>     p = 1) #>  #> Change points: #> 609  #>  #> Cost values: #> 304.2952 228.4288  #>  #> Parameters: #>   segment 1 segment 2 #> 1 0.5648258 0.2227463 plot(result)"},{"path":"https://fastcpd.xingchi.li/index.html","id":"ar3-model-with-innovation-standard-deviation-3","dir":"","previous_headings":"Examples","what":"ar(3) model with innovation standard deviation 3","title":"Fast Change Point Detection via Sequential Gradient Descent","text":"","code":"library(fastcpd) set.seed(1) n <- 1000 p <- 1 x <- rep(0, n + 3) for (i in 1:600) {   x[i + 3] <- 0.6 * x[i + 2] - 0.2 * x[i + 1] + 0.1 * x[i] + rnorm(1, 0, 3) } for (i in 601:1000) {   x[i + 1] <- 0.3 * x[i + 2] + 0.4 * x[i + 1] + 0.2 * x[i] + rnorm(1, 0, 3) } result <- fastcpd(   formula = ~ . - 1,   data = data.frame(x = x),   p = 3,   family = \"ar\" ) summary(result) #>  #> Call: #> fastcpd(formula = ~. - 1, data = data.frame(x = x), family = \"ar\",  #>     p = 3) #>  #> Change points: #> 615  #>  #> Cost values: #> 2753.547 2022.597  #>  #> Parameters: #>     segment 1   segment 2 #> 1  0.57616905  0.13006290 #> 2 -0.21476408 -0.03084403 #> 3  0.07938272 -0.04544551 plot(result)"},{"path":"https://fastcpd.xingchi.li/index.html","id":"custom-logistic-regression","dir":"","previous_headings":"Examples","what":"custom logistic regression","title":"Fast Change Point Detection via Sequential Gradient Descent","text":"","code":"library(fastcpd) set.seed(1) p <- 5 x <- matrix(rnorm(375 * p, 0, 1), ncol = p) theta <- rbind(rnorm(p, 0, 1), rnorm(p, 2, 1)) y <- c(   rbinom(200, 1, 1 / (1 + exp(-x[1:200, ] %*% theta[1, ]))),   rbinom(175, 1, 1 / (1 + exp(-x[201:375, ] %*% theta[2, ]))) ) data <- data.frame(y = y, x = x) result_builtin <- suppressWarnings(fastcpd(   formula = y ~ . - 1,   data = data,   family = \"binomial\" )) logistic_loss <- function(data, theta) {   x <- data[, -1]   y <- data[, 1]   u <- x %*% theta   nll <- -y * u + log(1 + exp(u))   nll[u > 10] <- -y[u > 10] * u[u > 10] + u[u > 10]   sum(nll) } logistic_loss_gradient <- function(data, theta) {   x <- data[nrow(data), -1]   y <- data[nrow(data), 1]   c(-(y - 1 / (1 + exp(-x %*% theta)))) * x } logistic_loss_hessian <- function(data, theta) {   x <- data[nrow(data), -1]   prob <- 1 / (1 + exp(-x %*% theta))   (x %o% x) * c((1 - prob) * prob) } result_custom <- fastcpd(   formula = y ~ . - 1,   data = data,   epsilon = 1e-5,   cost = logistic_loss,   cost_gradient = logistic_loss_gradient,   cost_hessian = logistic_loss_hessian ) cat(   \"Change points detected by built-in logistic regression model: \",   result_builtin@cp_set, \"\\n\",   \"Change points detected by custom logistic regression model: \",   result_custom@cp_set, \"\\n\",   sep = \"\" ) #> Change points detected by built-in logistic regression model: 200 #> Change points detected by custom logistic regression model: 201 result_custom_two_epochs <- fastcpd(   formula = y ~ . - 1,   data = data,   k = function(x) 1,   epsilon = 1e-5,   cost = logistic_loss,   cost_gradient = logistic_loss_gradient,   cost_hessian = logistic_loss_hessian ) summary(result_custom_two_epochs) #>  #> Call: #> fastcpd(formula = y ~ . - 1, data = data, k = function(x) 1,  #>     epsilon = 1e-05, cost = logistic_loss, cost_gradient = logistic_loss_gradient,  #>     cost_hessian = logistic_loss_hessian) #>  #> Change points: #> 200  #>  #> Parameters: #>    segment 1  segment 2 #> 1 -0.6235240  2.0066479 #> 2 -1.6767614  1.6278889 #> 3 -1.7973433  4.6422022 #> 4 -0.4842969 -0.1521062 #> 5  2.0797875  2.4047092"},{"path":"https://fastcpd.xingchi.li/index.html","id":"custom-cost-function-mean-change","dir":"","previous_headings":"Examples","what":"custom cost function mean change","title":"Fast Change Point Detection via Sequential Gradient Descent","text":"","code":"library(fastcpd) set.seed(1) p <- 1 data <- rbind(   mvtnorm::rmvnorm(300, mean = rep(0, p), sigma = diag(100, p)),   mvtnorm::rmvnorm(400, mean = rep(50, p), sigma = diag(100, p)),   mvtnorm::rmvnorm(300, mean = rep(2, p), sigma = diag(100, p)) ) segment_count_guess <- 10 block_size <- max(floor(sqrt(nrow(data)) / (segment_count_guess + 1)), 2) block_count <- floor(nrow(data) / block_size) data_all_vars <- rep(0, block_count) for (block_index in seq_len(block_count)) {   block_start <- (block_index - 1) * block_size + 1   block_end <- if (block_index < block_count) {     block_index * block_size   } else {     nrow(data)   }   data_all_vars[block_index] <- var(data[block_start:block_end, ]) } data_all_var <- mean(data_all_vars) mean_loss <- function(data) {   n <- nrow(data)   n / 2 * (     log(data_all_var) + log(2 * pi) +       sum((data - colMeans(data))^2 / data_all_var) / n   ) } mean_loss_result <- fastcpd(   formula = ~ . - 1,   data = data.frame(data),   beta = (p + 1) * log(nrow(data)) / 2,   p = p,   cost = mean_loss ) summary(mean_loss_result) #>  #> Call: #> fastcpd(formula = ~. - 1, data = data.frame(data), beta = (p +  #>     1) * log(nrow(data))/2, p = p, cost = mean_loss) #>  #> Change points: #> 300 700"},{"path":"https://fastcpd.xingchi.li/index.html","id":"custom-cost-function-multivariate-mean-change","dir":"","previous_headings":"Examples","what":"custom cost function multivariate mean change","title":"Fast Change Point Detection via Sequential Gradient Descent","text":"","code":"library(fastcpd) set.seed(1) p <- 3 data <- rbind(   mvtnorm::rmvnorm(300, mean = rep(0, p), sigma = diag(100, p)),   mvtnorm::rmvnorm(400, mean = rep(50, p), sigma = diag(100, p)),   mvtnorm::rmvnorm(300, mean = rep(2, p), sigma = diag(100, p)) ) segment_count_guess <- 5 block_size <- max(floor(sqrt(nrow(data)) / (segment_count_guess + 1)), 2) block_count <- floor(nrow(data) / block_size) data_all_covs <- array(NA, dim = c(block_count, p, p)) for (block_index in seq_len(block_count)) {   block_start <- (block_index - 1) * block_size + 1   block_end <- if (block_index < block_count) {     block_index * block_size   } else {     nrow(data)   }   data_all_covs[block_index, , ] <- cov(data[block_start:block_end, ]) } data_all_cov <- colMeans(data_all_covs) mean_loss <- function(data) {   n <- nrow(data)   demeaned_data <- sweep(data, 2, colMeans(data))   n / 2 * (     log(det(data_all_cov)) + p * log(2 * pi) +       sum(diag(solve(data_all_cov, crossprod(demeaned_data)))) / n   ) } mean_loss_result <- fastcpd(   formula = ~ . - 1,   data = data.frame(data),   beta = (p + 1) * log(nrow(data)) / 2,   p = p,   cost = mean_loss ) summary(mean_loss_result) #>  #> Call: #> fastcpd(formula = ~. - 1, data = data.frame(data), beta = (p +  #>     1) * log(nrow(data))/2, p = p, cost = mean_loss) #>  #> Change points: #> 300 700"},{"path":"https://fastcpd.xingchi.li/index.html","id":"custom-cost-function-variance-change","dir":"","previous_headings":"Examples","what":"custom cost function variance change","title":"Fast Change Point Detection via Sequential Gradient Descent","text":"","code":"library(fastcpd) set.seed(1) p <- 1 data <- rbind.data.frame(   mvtnorm::rmvnorm(300, mean = rep(0, p), sigma = diag(1, p)),   mvtnorm::rmvnorm(400, mean = rep(0, p), sigma = diag(50, p)),   mvtnorm::rmvnorm(300, mean = rep(0, p), sigma = diag(2, p)) ) data_all_mean <- colMeans(data) var_loss <- function(data) {   n <- nrow(data)   data_cov <- crossprod(sweep(data, 2, data_all_mean)) / (n - 1)   n / 2 * (log(data_cov) + log(2 * pi) + (n - 1) / n) } var_loss_result <- fastcpd(   formula = ~ . - 1,   data = data,   beta = (p + 1) * log(nrow(data)) / 2,   p = p,   cost = var_loss ) summary(var_loss_result) #>  #> Call: #> fastcpd(formula = ~. - 1, data = data, beta = (p + 1) * log(nrow(data))/2,  #>     p = p, cost = var_loss) #>  #> Change points: #> 300 699"},{"path":"https://fastcpd.xingchi.li/index.html","id":"custom-cost-function-multivariate-variance-change","dir":"","previous_headings":"Examples","what":"custom cost function multivariate variance change","title":"Fast Change Point Detection via Sequential Gradient Descent","text":"","code":"library(fastcpd) set.seed(1) p <- 3 data <- rbind.data.frame(   mvtnorm::rmvnorm(     300, rep(0, p), crossprod(matrix(runif(p^2) * 2 - 1, p))   ),   mvtnorm::rmvnorm(     400, rep(0, p), crossprod(matrix(runif(p^2) * 2 - 1, p))   ),   mvtnorm::rmvnorm(     300, rep(0, p), crossprod(matrix(runif(p^2) * 2 - 1, p))   ) ) data_all_mean <- colMeans(data) var_loss <- function(data) {   n <- nrow(data)   p <- ncol(data)   if (n < p) {     data_cov <- diag(p)   } else {     data_cov <- crossprod(sweep(data, 2, data_all_mean)) / (n - 1)   }   n / 2 * (log(det(data_cov)) + p * log(2 * pi) + p * (n - 1) / n) } var_loss_result <- fastcpd(   formula = ~ . - 1,   data = data,   beta = (p^2 + 1) * log(nrow(data)) / 2,   trim = 0.1,   p = p^2,   cost = var_loss ) summary(var_loss_result) #>  #> Call: #> fastcpd(formula = ~. - 1, data = data, beta = (p^2 + 1) * log(nrow(data))/2,  #>     trim = 0.1, p = p^2, cost = var_loss) #>  #> Change points: #> 300 700"},{"path":"https://fastcpd.xingchi.li/index.html","id":"custom-cost-function-mean-or-variance-change","dir":"","previous_headings":"Examples","what":"custom cost function mean or variance change","title":"Fast Change Point Detection via Sequential Gradient Descent","text":"","code":"library(fastcpd) set.seed(1) p <- 1 data <- rbind.data.frame(   mvtnorm::rmvnorm(300, mean = rep(0, p), sigma = diag(1, p)),   mvtnorm::rmvnorm(400, mean = rep(10, p), sigma = diag(1, p)),   mvtnorm::rmvnorm(300, mean = rep(0, p), sigma = diag(50, p)),   mvtnorm::rmvnorm(300, mean = rep(0, p), sigma = diag(1, p)),   mvtnorm::rmvnorm(400, mean = rep(10, p), sigma = diag(1, p)),   mvtnorm::rmvnorm(300, mean = rep(10, p), sigma = diag(50, p)) ) meanvar_loss <- function(data) {   n <- nrow(data)   data_cov <- 1   if (n > 1) {     data_cov <- var(data)   }   n / 2 * (log(data_cov) + log(2 * pi) + (n - 1) / n) } meanvar_loss_result <- fastcpd(   formula = ~ . - 1,   data = data,   beta = (p^2 + p + 1) * log(nrow(data)) / 2,   p = p^2 + p,   cost = meanvar_loss ) summary(meanvar_loss_result) #>  #> Call: #> fastcpd(formula = ~. - 1, data = data, beta = (p^2 + p + 1) *  #>     log(nrow(data))/2, p = p^2 + p, cost = meanvar_loss) #>  #> Change points: #> 300 700 1000 1300 1700"},{"path":"https://fastcpd.xingchi.li/index.html","id":"custom-cost-function-multivariate-mean-or-variance-change","dir":"","previous_headings":"Examples","what":"custom cost function multivariate mean or variance change","title":"Fast Change Point Detection via Sequential Gradient Descent","text":"","code":"library(fastcpd) set.seed(1) p <- 3 data <- rbind.data.frame(   mvtnorm::rmvnorm(300, mean = rep(0, p), sigma = diag(1, p)),   mvtnorm::rmvnorm(400, mean = rep(10, p), sigma = diag(1, p)),   mvtnorm::rmvnorm(300, mean = rep(0, p), sigma = diag(50, p)),   mvtnorm::rmvnorm(300, mean = rep(0, p), sigma = diag(1, p)),   mvtnorm::rmvnorm(400, mean = rep(10, p), sigma = diag(1, p)),   mvtnorm::rmvnorm(300, mean = rep(10, p), sigma = diag(50, p)) ) meanvar_loss <- function(data) {   n <- nrow(data)   p <- ncol(data)   if (n <= p) {     data_cov <- diag(p)   } else {     data_cov <- cov(data)   }   n / 2 * (log(det(data_cov)) + p * log(2 * pi) + p * (n - 1) / n) } meanvar_loss_result <- fastcpd(   formula = ~ . - 1,   data = data,   beta = (p^2 + p + 1) * log(nrow(data)) / 2,   trim = 0.01,   p = p^2 + p,   cost = meanvar_loss ) summary(meanvar_loss_result) #>  #> Call: #> fastcpd(formula = ~. - 1, data = data, beta = (p^2 + p + 1) *  #>     log(nrow(data))/2, trim = 0.01, p = p^2 + p, cost = meanvar_loss) #>  #> Change points: #> 300 700 1000 1300 1700"},{"path":"https://fastcpd.xingchi.li/index.html","id":"custom-cost-function-huber-regression","dir":"","previous_headings":"Examples","what":"custom cost function huber regression","title":"Fast Change Point Detection via Sequential Gradient Descent","text":"","code":"library(fastcpd) set.seed(1) n <- 400 + 300 + 500 p <- 5 x <- mvtnorm::rmvnorm(n, mean = rep(0, p), sigma = diag(p)) theta <- rbind(   mvtnorm::rmvnorm(1, mean = rep(0, p - 3), sigma = diag(p - 3)),   mvtnorm::rmvnorm(1, mean = rep(5, p - 3), sigma = diag(p - 3)),   mvtnorm::rmvnorm(1, mean = rep(9, p - 3), sigma = diag(p - 3)) ) theta <- cbind(theta, matrix(0, 3, 3)) theta <- theta[rep(seq_len(3), c(400, 300, 500)), ] y_true <- rowSums(x * theta) factor <- c(   2 * stats::rbinom(400, size = 1, prob = 0.95) - 1,   2 * stats::rbinom(300, size = 1, prob = 0.95) - 1,   2 * stats::rbinom(500, size = 1, prob = 0.95) - 1 ) y <- factor * y_true + stats::rnorm(n) data <- cbind.data.frame(y, x) huber_threshold <- 1 huber_loss <- function(data, theta) {   residual <- data[, 1] - data[, -1, drop = FALSE] %*% theta   indicator <- abs(residual) <= huber_threshold   sum(     residual^2 / 2 * indicator +       huber_threshold * (         abs(residual) - huber_threshold / 2       ) * (1 - indicator)   ) } huber_loss_gradient <- function(data, theta) {   residual <- c(data[nrow(data), 1] - data[nrow(data), -1] %*% theta)   if (abs(residual) <= huber_threshold) {     -residual * data[nrow(data), -1]   } else {     -huber_threshold * sign(residual) * data[nrow(data), -1]   } } huber_loss_hessian <- function(data, theta) {   residual <- c(data[nrow(data), 1] - data[nrow(data), -1] %*% theta)   if (abs(residual) <= huber_threshold) {     outer(data[nrow(data), -1], data[nrow(data), -1])   } else {     0.01 * diag(length(theta))   } } huber_regression_result <- fastcpd(   formula = y ~ . - 1,   data = data,   beta = (p + 1) * log(n) / 2,   cost = huber_loss,   cost_gradient = huber_loss_gradient,   cost_hessian = huber_loss_hessian ) summary(huber_regression_result) #>  #> Call: #> fastcpd(formula = y ~ . - 1, data = data, beta = (p + 1) * log(n)/2,  #>     cost = huber_loss, cost_gradient = huber_loss_gradient, cost_hessian = huber_loss_hessian) #>  #> Change points: #> 401 726  #>  #> Parameters: #>     segment 1   segment 2    segment 3 #> 1 -0.52615415  2.77991463  8.744706508 #> 2 -1.02443443  5.06390528  9.506534878 #> 3 -0.09220421  0.01647923 -0.008908851 #> 4 -0.01326592 -0.08103008 -0.047909865 #> 5  0.02526703  0.01329142  0.025171681"},{"path":"https://fastcpd.xingchi.li/index.html","id":"contact-us","dir":"","previous_headings":"","what":"Contact us","title":"Fast Change Point Detection via Sequential Gradient Descent","text":"Encountered bug unintended behavior? File ticket GitHub Issues. Contact authors specified DESCRIPTION.","code":""},{"path":[]},{"path":[]},{"path":"https://fastcpd.xingchi.li/reference/fastcpd-class.html","id":null,"dir":"Reference","previous_headings":"","what":"An S4 class to store the output created with fastcpd — fastcpd-class","title":"An S4 class to store the output created with fastcpd — fastcpd-class","text":"S4 class stores output fastcpd. fastcpd object consist several slots including call fastcpd, data used, family model, change points, cost values, residuals, estimated parameters boolean indicating whether model fitted change points change points parameters, can select using @.","code":""},{"path":"https://fastcpd.xingchi.li/reference/fastcpd-class.html","id":"slots","dir":"Reference","previous_headings":"","what":"Slots","title":"An S4 class to store the output created with fastcpd — fastcpd-class","text":"call call function `fastcpd`. data data passed `fastcpd` function. family family model. cp_set set change points. cost_values cost function values segment. residuals residuals segment. Used built-families. thetas estimated parameters segment. Used built-families. cp_only boolean indicating whether `fastcpd` run return change points change points estimated parameters cost values segment.","code":""},{"path":"https://fastcpd.xingchi.li/reference/fastcpd.html","id":null,"dir":"Reference","previous_headings":"","what":"Find change points efficiently — fastcpd","title":"Find change points efficiently — fastcpd","text":"fastcpd takes formulas, data, families extra parameters returns fastcpd object.","code":""},{"path":"https://fastcpd.xingchi.li/reference/fastcpd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find change points efficiently — fastcpd","text":"","code":"fastcpd(   formula = y ~ . - 1,   data,   beta = NULL,   segment_count = 10,   trim = 0.025,   momentum_coef = 0,   k = function(x) 0,   family = NULL,   epsilon = 1e-10,   min_prob = 10^10,   winsorise_minval = -20,   winsorise_maxval = 20,   p = ncol(data) - 1,   cost = NULL,   cost_gradient = NULL,   cost_hessian = NULL,   cp_only = FALSE,   vanilla_percentage = 0 )"},{"path":"https://fastcpd.xingchi.li/reference/fastcpd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find change points efficiently — fastcpd","text":"formula formula object specifying model fitted. optional response variable left hand side formula covariates right hand side. intercept term removed formula. response variable necessary data considered regression type. example, mean variance change model necessarily response variables. default intercept column added data similar lm function R. Thus suggested user remove intercept term formula appending - 1 formula. default formula suitable regression data sets one-dimensional response variable rest covariates without intercept. naming variables used formula consistent column names data frame provided data. data data frame containing data segmented row denotes data point. one-dimensional response variable regression settings, first column response variable rest covariates. response necessary case mean change variance change, case formula need adjusted accordingly. beta Initial cost value specified algorithm paper. proper choice value, please refer paper. specified, BIC criterion used obtain proper value, .e., beta = (p + 1) * log(nrow(data)) / 2. segment_count Number segments initial guess. specified, initial guess number segments 10. trim Trimming boundary change points change point close boundary counted change point. parameter also specifies minimum distance two change points. .   several change points mutual distances smaller trim * nrow(data), change points merged one single change point. value parameter 0 1. momentum_coef Momentum coefficient applied update. parameter used loss function bad-shaped maintaining momentum previous update desired. Default value 0, meaning algorithm maintain momentum default. k Function number epochs SGD. k function taking parameter x meaning current number data points considered since last segmentaion. return value function integer indicating many epochs performed apart default update. default function returns 0, meaning multiple epochs used update parameters. Example usage:   function perform 3 epochs first quarter data, 2 epochs second quarter data, 1 epoch third quarter data multiple epochs last quarter data. Experiments show performing multiple epochs significantly affect performance algorithm. parameter left users tune performance algorithm result ideal. Details discussed paper. family Family model. Can \"gaussian\", \"binomial\", \"poisson\", \"lasso\", \"custom\" NULL. simplicity, user can also omit parameter, indicating using cost functions. Omitting parameter specifying parameter \"custom\" NULL, case, users must specify cost function, optional gradient corresponding Hessian matrix functions. epsilon Epsilon avoid numerical issues. used Hessian computation Logistic Regression Poisson Regression. min_prob Minimum probability avoid numerical issues. used Poisson Regression. winsorise_minval Minimum value parameter Poisson Regression winsorised. winsorise_maxval Maximum value parameter Poisson Regression winsorised. p Number covariates model. specified, number covariates inferred data, .e., p = ncol(data) - 1. cost Cost function used. following two parameters specified time family. specified, default negative log-likelihood corresponding family. Custom cost functions can provided following two formats: cost = function(data) {...} cost = function(data, theta) {...} methods, users implement cost value calculation based data provided, data parameter can considered segment original data frame form matrix. first method used cost function explicit solution, case cost function value can calculated directly data. second method used cost function explicit solution, case cost function value can calculated data estimated parameters. case one data argument provided, fastcpd performs vanilla PELT algorithm since parameter updating performed. cost_gradient Gradient function custom cost function. Example usage:   gradient function take two parameters, first one segment data format matrix, second one estimated parameters. gradient function return gradient cost function respect data parameters. cost_hessian Hessian function custom cost function. Similar gradient function, Hessian function take two parameters, first one segment data format matrix, second one estimated parameters. Hessian function return Hessian matrix cost function respect data parameters. cp_only TRUE, change points returned. Otherwise, cost function values together estimated parameters segment also returned. default value set FALSE plot can used visualize results built-model. cp_only performance impact algorithm, since cost values estimated parameters segment need calculated stored. users interested change points, setting cp_only TRUE help computational cost. vanilla_percentage many data processed vanilla PELT. Range 0 1. fastcpd algorithm based gradient descent thus starting estimate can crucial. beginning algorithm, vanilla PELT can performed obtain relatively accurate estimate parameters despite small amount data used. set 0, data processed sequential gradient descnet. set 1, data processed vaniall PELT. cost function explicit solution, .e. depend coefficients like mean change case, parameter set 1. value set 0 1, first vanilla_percentage * nrow(data) data points processed vanilla PELT rest processed sequential gradient descent.","code":"k = function(x) {     if (x < n / segment_count / 4 * 1) 3     else if (x < n / segment_count / 4 * 2) 2     else if (x < n / segment_count / 4 * 3) 1     else 0   } cost_gradient = function(data, theta) {     ...     return(gradient)   }"},{"path":"https://fastcpd.xingchi.li/reference/fastcpd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find change points efficiently — fastcpd","text":"class fastcpd object.","code":""},{"path":"https://fastcpd.xingchi.li/reference/fastcpd.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Find change points efficiently — fastcpd","text":"Zhang X, Dawn T (2023). ``Sequential Gradient Descent Quasi-Newton's Method Change-Point Analysis.'' Ruiz, Francisco, Dy, Jennifer, van de Meent, Jan-Willem (eds.), Proceedings 26th International Conference Artificial Intelligence Statistics, volume 206 series Proceedings Machine Learning Research, 1129-1143. https://proceedings.mlr.press/v206/zhang23b.html.","code":""},{"path":"https://fastcpd.xingchi.li/reference/fastcpd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find change points efficiently — fastcpd","text":"","code":"# \\donttest{ if (!requireNamespace(\"ggplot2\", quietly = TRUE)) utils::install.packages(   \"ggplot2\", repos = \"https://cloud.r-project.org\", quiet = TRUE )  ### linear regression library(fastcpd) set.seed(1) p <- 3 x <- mvtnorm::rmvnorm(300, rep(0, p), diag(p)) theta_0 <- rbind(c(1, 1.2, -1), c(-1, 0, 0.5), c(0.5, -0.3, 0.2)) y <- c(   x[1:100, ] %*% theta_0[1, ] + rnorm(100, 0, 1),   x[101:200, ] %*% theta_0[2, ] + rnorm(100, 0, 1),   x[201:300, ] %*% theta_0[3, ] + rnorm(100, 0, 1) ) result <- fastcpd(   formula = y ~ . - 1,   data = data.frame(y = y, x = x),   family = \"gaussian\" ) plot(result)  summary(result) #>  #> Call: #> fastcpd(formula = y ~ . - 1, data = data.frame(y = y, x = x),  #>     family = \"gaussian\") #>  #> Change points: #> 98 202  #>  #> Cost values: #> 53.44023 53.1441 45.04974  #>  #> Parameters: #>    segment 1   segment 2  segment 3 #> 1  0.9704022 -1.07884004  0.5925092 #> 2  1.1786074 -0.01757927 -0.5287126 #> 3 -0.9258587  0.63906143  0.1929411  ### linear regression with one-dimensional covariate library(fastcpd) set.seed(1) p <- 1 x <- mvtnorm::rmvnorm(300, rep(0, p), diag(p)) theta_0 <- matrix(c(1, -1, 0.5)) y <- c(   x[1:100, ] * theta_0[1, ] + rnorm(100, 0, 1),   x[101:200, ] * theta_0[2, ] + rnorm(100, 0, 1),   x[201:300, ] * theta_0[3, ] + rnorm(100, 0, 1) ) result <- fastcpd(   formula = y ~ . - 1,   data = data.frame(y = y, x = x),   family = \"gaussian\" ) plot(result)  summary(result) #>  #> Call: #> fastcpd(formula = y ~ . - 1, data = data.frame(y = y, x = x),  #>     family = \"gaussian\") #>  #> Change points: #> 100 194  #>  #> Cost values: #> 48.71927 57.20738 63.15088  #>  #> Parameters: #>   segment 1  segment 2 segment 3 #> 1 0.9520606 -0.8054074 0.3692224  ### linear regression with noise variance not equal to 1 library(fastcpd) set.seed(1) p <- 4 n <- 300 cp <- c(100, 200) x <- mvtnorm::rmvnorm(n, rep(0, p), diag(p)) theta_0 <- rbind(c(1, 3.2, -1, 0), c(-1, -0.5, 2.5, -2), c(0.8, -0.3, 1, 1)) y <- c(   x[1:cp[1], ] %*% theta_0[1, ] + rnorm(cp[1], 0, sd = 3),   x[(cp[1] + 1):cp[2], ] %*% theta_0[2, ] + rnorm(cp[2] - cp[1], 0, sd = 3),   x[(cp[2] + 1):n, ] %*% theta_0[3, ] + rnorm(n - cp[2], 0, sd = 3) )  result <- fastcpd(   data = data.frame(y = y, x = x),   family = \"gaussian\" ) summary(result) #>  #> Call: #> fastcpd(data = data.frame(y = y, x = x), family = \"gaussian\") #>  #> Change points: #> 100 201  #>  #> Cost values: #> 499.5254 328.5244 459.3819  #>  #> Parameters: #>    segment 1  segment 2  segment 3 #> 1  0.7054739 -0.5373328 0.23439463 #> 2  0.8005173 -0.8915565 0.87884516 #> 3  3.6097492 -0.5539604 0.03698789 #> 4 -1.3438206  2.2831450 1.01253653 #> 5  0.1352143 -2.0567371 1.28948015  ### logistic regression library(fastcpd) set.seed(1) x <- matrix(rnorm(1500, 0, 1), ncol = 5) theta <- rbind(rnorm(5, 0, 1), rnorm(5, 2, 1)) y <- c(   rbinom(125, 1, 1 / (1 + exp(-x[1:125, ] %*% theta[1, ]))),   rbinom(175, 1, 1 / (1 + exp(-x[126:300, ] %*% theta[2, ]))) ) result <- suppressWarnings(fastcpd(   formula = y ~ . - 1,   data = data.frame(y = y, x = x),   family = \"binomial\" )) summary(result) #>  #> Call: #> fastcpd(formula = y ~ . - 1, data = data.frame(y = y, x = x),  #>     family = \"binomial\") #>  #> Change points: #> 126  #>  #> Cost values: #> 56.90525 30.76875  #>  #> Parameters: #>    segment 1 segment 2 #> 1  0.7259293  1.878525 #> 2 -1.0294802  2.704376 #> 3  1.0576503  3.702310 #> 4 -0.8812767  2.258796 #> 5  0.2419351  2.524173  ### poisson regression library(fastcpd) set.seed(1) p <- 3 x <- mvtnorm::rmvnorm(1500, rep(0, p), diag(p)) delta <- rnorm(p) theta_0 <- c(1, 1.2, -1) y <- c(   rpois(300, exp(x[1:300, ] %*% theta_0)),   rpois(400, exp(x[301:700, ] %*% (theta_0 + delta))),   rpois(300, exp(x[701:1000, ] %*% theta_0)),   rpois(100, exp(x[1001:1100, ] %*% (theta_0 - delta))),   rpois(200, exp(x[1101:1300, ] %*% theta_0)),   rpois(200, exp(x[1301:1500, ] %*% (theta_0 + delta))) ) result <- fastcpd(   formula = y ~ . - 1,   data = data.frame(y = y, x = x),   beta = (p + 1) * log(1500) / 2,   k = function(x) 0,   family = \"poisson\",   epsilon = 1e-5 ) summary(result) #>  #> Call: #> fastcpd(formula = y ~ . - 1, data = data.frame(y = y, x = x),  #>     beta = (p + 1) * log(1500)/2, k = function(x) 0, family = \"poisson\",  #>     epsilon = 1e-05) #>  #> Change points: #> 329 728 1021 1107 1325  #>  #> Cost values: #> 14425.87 13971.23 697.2187 107.5353 380.7153 51.93594  #>  #> Parameters: #>     segment 1  segment 2  segment 3  segment 4 segment 5  segment 6 #> 1  2.60927673  1.9255183  0.7405125 -0.3965022  1.117753  2.5479308 #> 2  0.02398457  0.1068924  1.4721444  1.8677797  1.019035  0.4947115 #> 3 -1.34361104 -2.7353603 -0.8906937  0.4651667 -1.178933 -2.5038966 result_two_epochs <- fastcpd(   formula = y ~ . - 1,   data = data.frame(y = y, x = x),   beta = (p + 1) * log(1500) / 2,   k = function(x) 1,   family = \"poisson\",   epsilon = 1e-4 ) summary(result_two_epochs) #>  #> Call: #> fastcpd(formula = y ~ . - 1, data = data.frame(y = y, x = x),  #>     beta = (p + 1) * log(1500)/2, k = function(x) 1, family = \"poisson\",  #>     epsilon = 1e-04) #>  #> Change points: #> 328 716 1020 1102 1323  #>  #> Cost values: #> 14417.14 2976.961 717.4614 31.48528 296.6285 53.94423  #>  #> Parameters: #>     segment 1  segment 2  segment 3  segment 4 segment 5  segment 6 #> 1  2.60955822  2.4484869  0.7832980 -0.5008107  1.105317  2.5479958 #> 2  0.02371536  0.4084502  1.4456715  1.9282798  1.057743  0.4951862 #> 3 -1.34277129 -2.5426556 -0.8989812  0.5197285 -1.128259 -2.5035143  ### penalized linear regression library(fastcpd) set.seed(1) n <- 1500 p_true <- 6 p <- 50 x <- mvtnorm::rmvnorm(1500, rep(0, p), diag(p)) theta_0 <- rbind(   runif(p_true, -5, -2),   runif(p_true, -3, 3),   runif(p_true, 2, 5),   runif(p_true, -5, 5) ) theta_0 <- cbind(theta_0, matrix(0, ncol = p - p_true, nrow = 4)) y <- c(   x[1:300, ] %*% theta_0[1, ] + rnorm(300, 0, 1),   x[301:700, ] %*% theta_0[2, ] + rnorm(400, 0, 1),   x[701:1000, ] %*% theta_0[3, ] + rnorm(300, 0, 1),   x[1001:1500, ] %*% theta_0[4, ] + rnorm(500, 0, 1) ) result <- fastcpd(   formula = y ~ . - 1,   data = data.frame(y = y, x = x),   family = \"lasso\" ) plot(result)  summary(result) #>  #> Call: #> fastcpd(formula = y ~ . - 1, data = data.frame(y = y, x = x),  #>     family = \"lasso\") #>  #> Change points: #> 300 700 1000  #>  #> Cost values: #> 202.6103 254.6904 183.5909 302.4998  #>  #> Parameters: #> 50 x 4 sparse Matrix of class \"dgCMatrix\" #>       segment 1  segment 2 segment 3  segment 4 #>  [1,] -2.892654  0.3344843  4.046784  .         #>  [2,] -2.831352 -0.3687367  3.907948  3.1109044 #>  [3,] -2.817023 -0.1990682  2.574074  2.7732194 #>  [4,] -1.926208  0.4740742  3.322680 -0.5366242 #>  [5,] -3.066517 -0.4659526  2.092768 -3.3781507 #>  [6,] -1.842233  0.4168482  4.798087  .         #>  [7,]  .         .          .         .         #>  [8,]  .         .          .         .         #>  [9,]  .         .          .         .         #> [10,]  .         .          .         .         #> [11,]  .         .          .         .         #> [12,]  .         .          .         .         #> [13,]  .         .          .         .         #> [14,]  .         .          .         .         #> [15,]  .         .          .         .         #> [16,]  .         .          .         .         #> [17,]  .         .          .         .         #> [18,]  .         .          .         .         #> [19,]  .         .          .         .         #> [20,]  .         .          .         .         #> [21,]  .         .          .         .         #> [22,]  .         .          .         .         #> [23,]  .         .          .         .         #> [24,]  .         .          .         .         #> [25,]  .         .          .         .         #> [26,]  .         .          .         .         #> [27,]  .         .          .         .         #> [28,]  .         .          .         .         #> [29,]  .         .          .         .         #> [30,]  .         .          .         .         #> [31,]  .         .          .         .         #> [32,]  .         .          .         .         #> [33,]  .         .          .         .         #> [34,]  .         .          .         .         #> [35,]  .         .          .         .         #> [36,]  .         .          .         .         #> [37,]  .         .          .         .         #> [38,]  .         .          .         .         #> [39,]  .         .          .         .         #> [40,]  .         .          .         .         #> [41,]  .         .          .         .         #> [42,]  .         .          .         .         #> [43,]  .         .          .         .         #> [44,]  .         .          .         .         #> [45,]  .         .          .         .         #> [46,]  .         .          .         .         #> [47,]  .         .          .         .         #> [48,]  .         .          .         .         #> [49,]  .         .          .         .         #> [50,]  .         .          .         .          ### ar(1) model library(fastcpd) set.seed(1) n <- 1000 p <- 1 x <- rep(0, n + 1) for (i in 1:600) {   x[i + 1] <- 0.6 * x[i] + rnorm(1) } for (i in 601:1000) {   x[i + 1] <- 0.3 * x[i] + rnorm(1) } result <- fastcpd(   formula = ~ . - 1,   data = data.frame(x = x),   p = 1,   family = \"ar\" ) summary(result) #>  #> Call: #> fastcpd(formula = ~. - 1, data = data.frame(x = x), family = \"ar\",  #>     p = 1) #>  #> Change points: #> 609  #>  #> Cost values: #> 304.2952 228.4288  #>  #> Parameters: #>   segment 1 segment 2 #> 1 0.5648258 0.2227463 plot(result)   ### ar(3) model with innovation standard deviation 3 library(fastcpd) set.seed(1) n <- 1000 p <- 1 x <- rep(0, n + 3) for (i in 1:600) {   x[i + 3] <- 0.6 * x[i + 2] - 0.2 * x[i + 1] + 0.1 * x[i] + rnorm(1, 0, 3) } for (i in 601:1000) {   x[i + 1] <- 0.3 * x[i + 2] + 0.4 * x[i + 1] + 0.2 * x[i] + rnorm(1, 0, 3) } result <- fastcpd(   formula = ~ . - 1,   data = data.frame(x = x),   p = 3,   family = \"ar\" ) summary(result) #>  #> Call: #> fastcpd(formula = ~. - 1, data = data.frame(x = x), family = \"ar\",  #>     p = 3) #>  #> Change points: #> 615  #>  #> Cost values: #> 2753.547 2022.597  #>  #> Parameters: #>     segment 1   segment 2 #> 1  0.57616905  0.13006290 #> 2 -0.21476408 -0.03084403 #> 3  0.07938272 -0.04544551 plot(result)   ### custom logistic regression library(fastcpd) set.seed(1) p <- 5 x <- matrix(rnorm(375 * p, 0, 1), ncol = p) theta <- rbind(rnorm(p, 0, 1), rnorm(p, 2, 1)) y <- c(   rbinom(200, 1, 1 / (1 + exp(-x[1:200, ] %*% theta[1, ]))),   rbinom(175, 1, 1 / (1 + exp(-x[201:375, ] %*% theta[2, ]))) ) data <- data.frame(y = y, x = x) result_builtin <- suppressWarnings(fastcpd(   formula = y ~ . - 1,   data = data,   family = \"binomial\" )) logistic_loss <- function(data, theta) {   x <- data[, -1]   y <- data[, 1]   u <- x %*% theta   nll <- -y * u + log(1 + exp(u))   nll[u > 10] <- -y[u > 10] * u[u > 10] + u[u > 10]   sum(nll) } logistic_loss_gradient <- function(data, theta) {   x <- data[nrow(data), -1]   y <- data[nrow(data), 1]   c(-(y - 1 / (1 + exp(-x %*% theta)))) * x } logistic_loss_hessian <- function(data, theta) {   x <- data[nrow(data), -1]   prob <- 1 / (1 + exp(-x %*% theta))   (x %o% x) * c((1 - prob) * prob) } result_custom <- fastcpd(   formula = y ~ . - 1,   data = data,   epsilon = 1e-5,   cost = logistic_loss,   cost_gradient = logistic_loss_gradient,   cost_hessian = logistic_loss_hessian ) cat(   \"Change points detected by built-in logistic regression model: \",   result_builtin@cp_set, \"\\n\",   \"Change points detected by custom logistic regression model: \",   result_custom@cp_set, \"\\n\",   sep = \"\" ) #> Change points detected by built-in logistic regression model: 200 #> Change points detected by custom logistic regression model: 201 result_custom_two_epochs <- fastcpd(   formula = y ~ . - 1,   data = data,   k = function(x) 1,   epsilon = 1e-5,   cost = logistic_loss,   cost_gradient = logistic_loss_gradient,   cost_hessian = logistic_loss_hessian ) summary(result_custom_two_epochs) #>  #> Call: #> fastcpd(formula = y ~ . - 1, data = data, k = function(x) 1,  #>     epsilon = 1e-05, cost = logistic_loss, cost_gradient = logistic_loss_gradient,  #>     cost_hessian = logistic_loss_hessian) #>  #> Change points: #> 200  #>  #> Parameters: #>    segment 1  segment 2 #> 1 -0.6235240  2.0066479 #> 2 -1.6767614  1.6278889 #> 3 -1.7973433  4.6422022 #> 4 -0.4842969 -0.1521062 #> 5  2.0797875  2.4047092  ### custom cost function mean change library(fastcpd) set.seed(1) p <- 1 data <- rbind(   mvtnorm::rmvnorm(300, mean = rep(0, p), sigma = diag(100, p)),   mvtnorm::rmvnorm(400, mean = rep(50, p), sigma = diag(100, p)),   mvtnorm::rmvnorm(300, mean = rep(2, p), sigma = diag(100, p)) ) segment_count_guess <- 10 block_size <- max(floor(sqrt(nrow(data)) / (segment_count_guess + 1)), 2) block_count <- floor(nrow(data) / block_size) data_all_vars <- rep(0, block_count) for (block_index in seq_len(block_count)) {   block_start <- (block_index - 1) * block_size + 1   block_end <- if (block_index < block_count) {     block_index * block_size   } else {     nrow(data)   }   data_all_vars[block_index] <- var(data[block_start:block_end, ]) } data_all_var <- mean(data_all_vars) mean_loss <- function(data) {   n <- nrow(data)   n / 2 * (     log(data_all_var) + log(2 * pi) +       sum((data - colMeans(data))^2 / data_all_var) / n   ) } mean_loss_result <- fastcpd(   formula = ~ . - 1,   data = data.frame(data),   beta = (p + 1) * log(nrow(data)) / 2,   p = p,   cost = mean_loss ) summary(mean_loss_result) #>  #> Call: #> fastcpd(formula = ~. - 1, data = data.frame(data), beta = (p +  #>     1) * log(nrow(data))/2, p = p, cost = mean_loss) #>  #> Change points: #> 300 700   ### custom cost function multivariate mean change library(fastcpd) set.seed(1) p <- 3 data <- rbind(   mvtnorm::rmvnorm(300, mean = rep(0, p), sigma = diag(100, p)),   mvtnorm::rmvnorm(400, mean = rep(50, p), sigma = diag(100, p)),   mvtnorm::rmvnorm(300, mean = rep(2, p), sigma = diag(100, p)) ) segment_count_guess <- 5 block_size <- max(floor(sqrt(nrow(data)) / (segment_count_guess + 1)), 2) block_count <- floor(nrow(data) / block_size) data_all_covs <- array(NA, dim = c(block_count, p, p)) for (block_index in seq_len(block_count)) {   block_start <- (block_index - 1) * block_size + 1   block_end <- if (block_index < block_count) {     block_index * block_size   } else {     nrow(data)   }   data_all_covs[block_index, , ] <- cov(data[block_start:block_end, ]) } data_all_cov <- colMeans(data_all_covs) mean_loss <- function(data) {   n <- nrow(data)   demeaned_data <- sweep(data, 2, colMeans(data))   n / 2 * (     log(det(data_all_cov)) + p * log(2 * pi) +       sum(diag(solve(data_all_cov, crossprod(demeaned_data)))) / n   ) } mean_loss_result <- fastcpd(   formula = ~ . - 1,   data = data.frame(data),   beta = (p + 1) * log(nrow(data)) / 2,   p = p,   cost = mean_loss ) summary(mean_loss_result) #>  #> Call: #> fastcpd(formula = ~. - 1, data = data.frame(data), beta = (p +  #>     1) * log(nrow(data))/2, p = p, cost = mean_loss) #>  #> Change points: #> 300 700   ### custom cost function variance change library(fastcpd) set.seed(1) p <- 1 data <- rbind.data.frame(   mvtnorm::rmvnorm(300, mean = rep(0, p), sigma = diag(1, p)),   mvtnorm::rmvnorm(400, mean = rep(0, p), sigma = diag(50, p)),   mvtnorm::rmvnorm(300, mean = rep(0, p), sigma = diag(2, p)) ) data_all_mean <- colMeans(data) var_loss <- function(data) {   n <- nrow(data)   data_cov <- crossprod(sweep(data, 2, data_all_mean)) / (n - 1)   n / 2 * (log(data_cov) + log(2 * pi) + (n - 1) / n) } var_loss_result <- fastcpd(   formula = ~ . - 1,   data = data,   beta = (p + 1) * log(nrow(data)) / 2,   p = p,   cost = var_loss ) summary(var_loss_result) #>  #> Call: #> fastcpd(formula = ~. - 1, data = data, beta = (p + 1) * log(nrow(data))/2,  #>     p = p, cost = var_loss) #>  #> Change points: #> 300 699   ### custom cost function multivariate variance change library(fastcpd) set.seed(1) p <- 3 data <- rbind.data.frame(   mvtnorm::rmvnorm(     300, rep(0, p), crossprod(matrix(runif(p^2) * 2 - 1, p))   ),   mvtnorm::rmvnorm(     400, rep(0, p), crossprod(matrix(runif(p^2) * 2 - 1, p))   ),   mvtnorm::rmvnorm(     300, rep(0, p), crossprod(matrix(runif(p^2) * 2 - 1, p))   ) ) data_all_mean <- colMeans(data) var_loss <- function(data) {   n <- nrow(data)   p <- ncol(data)   if (n < p) {     data_cov <- diag(p)   } else {     data_cov <- crossprod(sweep(data, 2, data_all_mean)) / (n - 1)   }   n / 2 * (log(det(data_cov)) + p * log(2 * pi) + p * (n - 1) / n) } var_loss_result <- fastcpd(   formula = ~ . - 1,   data = data,   beta = (p^2 + 1) * log(nrow(data)) / 2,   trim = 0.1,   p = p^2,   cost = var_loss ) summary(var_loss_result) #>  #> Call: #> fastcpd(formula = ~. - 1, data = data, beta = (p^2 + 1) * log(nrow(data))/2,  #>     trim = 0.1, p = p^2, cost = var_loss) #>  #> Change points: #> 300 700   ### custom cost function mean or variance change library(fastcpd) set.seed(1) p <- 1 data <- rbind.data.frame(   mvtnorm::rmvnorm(300, mean = rep(0, p), sigma = diag(1, p)),   mvtnorm::rmvnorm(400, mean = rep(10, p), sigma = diag(1, p)),   mvtnorm::rmvnorm(300, mean = rep(0, p), sigma = diag(50, p)),   mvtnorm::rmvnorm(300, mean = rep(0, p), sigma = diag(1, p)),   mvtnorm::rmvnorm(400, mean = rep(10, p), sigma = diag(1, p)),   mvtnorm::rmvnorm(300, mean = rep(10, p), sigma = diag(50, p)) ) meanvar_loss <- function(data) {   n <- nrow(data)   data_cov <- 1   if (n > 1) {     data_cov <- var(data)   }   n / 2 * (log(data_cov) + log(2 * pi) + (n - 1) / n) } meanvar_loss_result <- fastcpd(   formula = ~ . - 1,   data = data,   beta = (p^2 + p + 1) * log(nrow(data)) / 2,   p = p^2 + p,   cost = meanvar_loss ) summary(meanvar_loss_result) #>  #> Call: #> fastcpd(formula = ~. - 1, data = data, beta = (p^2 + p + 1) *  #>     log(nrow(data))/2, p = p^2 + p, cost = meanvar_loss) #>  #> Change points: #> 300 700 1000 1300 1700   ### custom cost function multivariate mean or variance change library(fastcpd) set.seed(1) p <- 3 data <- rbind.data.frame(   mvtnorm::rmvnorm(300, mean = rep(0, p), sigma = diag(1, p)),   mvtnorm::rmvnorm(400, mean = rep(10, p), sigma = diag(1, p)),   mvtnorm::rmvnorm(300, mean = rep(0, p), sigma = diag(50, p)),   mvtnorm::rmvnorm(300, mean = rep(0, p), sigma = diag(1, p)),   mvtnorm::rmvnorm(400, mean = rep(10, p), sigma = diag(1, p)),   mvtnorm::rmvnorm(300, mean = rep(10, p), sigma = diag(50, p)) ) meanvar_loss <- function(data) {   n <- nrow(data)   p <- ncol(data)   if (n <= p) {     data_cov <- diag(p)   } else {     data_cov <- cov(data)   }   n / 2 * (log(det(data_cov)) + p * log(2 * pi) + p * (n - 1) / n) } meanvar_loss_result <- fastcpd(   formula = ~ . - 1,   data = data,   beta = (p^2 + p + 1) * log(nrow(data)) / 2,   trim = 0.01,   p = p^2 + p,   cost = meanvar_loss ) summary(meanvar_loss_result) #>  #> Call: #> fastcpd(formula = ~. - 1, data = data, beta = (p^2 + p + 1) *  #>     log(nrow(data))/2, trim = 0.01, p = p^2 + p, cost = meanvar_loss) #>  #> Change points: #> 300 700 1000 1300 1700   ### custom cost function huber regression library(fastcpd) set.seed(1) n <- 400 + 300 + 500 p <- 5 x <- mvtnorm::rmvnorm(n, mean = rep(0, p), sigma = diag(p)) theta <- rbind(   mvtnorm::rmvnorm(1, mean = rep(0, p - 3), sigma = diag(p - 3)),   mvtnorm::rmvnorm(1, mean = rep(5, p - 3), sigma = diag(p - 3)),   mvtnorm::rmvnorm(1, mean = rep(9, p - 3), sigma = diag(p - 3)) ) theta <- cbind(theta, matrix(0, 3, 3)) theta <- theta[rep(seq_len(3), c(400, 300, 500)), ] y_true <- rowSums(x * theta) factor <- c(   2 * stats::rbinom(400, size = 1, prob = 0.95) - 1,   2 * stats::rbinom(300, size = 1, prob = 0.95) - 1,   2 * stats::rbinom(500, size = 1, prob = 0.95) - 1 ) y <- factor * y_true + stats::rnorm(n) data <- cbind.data.frame(y, x) huber_threshold <- 1 huber_loss <- function(data, theta) {   residual <- data[, 1] - data[, -1, drop = FALSE] %*% theta   indicator <- abs(residual) <= huber_threshold   sum(     residual^2 / 2 * indicator +       huber_threshold * (         abs(residual) - huber_threshold / 2       ) * (1 - indicator)   ) } huber_loss_gradient <- function(data, theta) {   residual <- c(data[nrow(data), 1] - data[nrow(data), -1] %*% theta)   if (abs(residual) <= huber_threshold) {     -residual * data[nrow(data), -1]   } else {     -huber_threshold * sign(residual) * data[nrow(data), -1]   } } huber_loss_hessian <- function(data, theta) {   residual <- c(data[nrow(data), 1] - data[nrow(data), -1] %*% theta)   if (abs(residual) <= huber_threshold) {     outer(data[nrow(data), -1], data[nrow(data), -1])   } else {     0.01 * diag(length(theta))   } } huber_regression_result <- fastcpd(   formula = y ~ . - 1,   data = data,   beta = (p + 1) * log(n) / 2,   cost = huber_loss,   cost_gradient = huber_loss_gradient,   cost_hessian = huber_loss_hessian ) summary(huber_regression_result) #>  #> Call: #> fastcpd(formula = y ~ . - 1, data = data, beta = (p + 1) * log(n)/2,  #>     cost = huber_loss, cost_gradient = huber_loss_gradient, cost_hessian = huber_loss_hessian) #>  #> Change points: #> 401 726  #>  #> Parameters: #>     segment 1   segment 2    segment 3 #> 1 -0.52615415  2.77991463  8.744706508 #> 2 -1.02443443  5.06390528  9.506534878 #> 3 -0.09220421  0.01647923 -0.008908851 #> 4 -0.01326592 -0.08103008 -0.047909865 #> 5  0.02526703  0.01329142  0.025171681 # }"},{"path":"https://fastcpd.xingchi.li/reference/fastcpd_ts.html","id":null,"dir":"Reference","previous_headings":"","what":"Find change points efficiently in time series data — fastcpd.ts","title":"Find change points efficiently in time series data — fastcpd.ts","text":"`fastcpd_ts` wrapper function `fastcpd` find   change points time series data. function similar `fastcpd`   except data time series data family one   \"ar\" \"var\".","code":""},{"path":"https://fastcpd.xingchi.li/reference/fastcpd_ts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find change points efficiently in time series data — fastcpd.ts","text":"","code":"fastcpd.ts(data, family = NULL, order = NULL, ...)  fastcpd_ts(data, family = NULL, order = NULL, ...)"},{"path":"https://fastcpd.xingchi.li/reference/fastcpd_ts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find change points efficiently in time series data — fastcpd.ts","text":"data numeric vector, matrix, data frame time series object. family character string specifying family time series. value one \"ar\" \"var\". order positive integer specifying order time series. ... arguments passed fastcpd.","code":""},{"path":"https://fastcpd.xingchi.li/reference/fastcpd_ts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find change points efficiently in time series data — fastcpd.ts","text":"class fastcpd object.","code":""},{"path":"https://fastcpd.xingchi.li/reference/plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot the data and the change points for a fastcpd object — plot.fastcpd","title":"Plot the data and the change points for a fastcpd object — plot.fastcpd","text":"Plot data change points fastcpd object","code":""},{"path":"https://fastcpd.xingchi.li/reference/plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot the data and the change points for a fastcpd object — plot.fastcpd","text":"","code":"# S3 method for fastcpd plot(x, ...)  # S4 method for fastcpd,missing plot(x, y, ...)"},{"path":"https://fastcpd.xingchi.li/reference/plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot the data and the change points for a fastcpd object — plot.fastcpd","text":"x fastcpd object. ... Ignored. y Ignored.","code":""},{"path":"https://fastcpd.xingchi.li/reference/plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot the data and the change points for a fastcpd object — plot.fastcpd","text":"return value, called plotting.","code":""},{"path":"https://fastcpd.xingchi.li/reference/print.html","id":null,"dir":"Reference","previous_headings":"","what":"Print the call and the change points for a fastcpd object — print.fastcpd","title":"Print the call and the change points for a fastcpd object — print.fastcpd","text":"Print call change points fastcpd object","code":""},{"path":"https://fastcpd.xingchi.li/reference/print.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print the call and the change points for a fastcpd object — print.fastcpd","text":"","code":"# S3 method for fastcpd print(x, ...)  # S4 method for fastcpd print(x, ...)"},{"path":"https://fastcpd.xingchi.li/reference/print.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print the call and the change points for a fastcpd object — print.fastcpd","text":"x fastcpd object. ... Ignored.","code":""},{"path":"https://fastcpd.xingchi.li/reference/print.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print the call and the change points for a fastcpd object — print.fastcpd","text":"Return (temporarily) invisible copy fastcpd object.   Called primarily printing change points model.","code":""},{"path":"https://fastcpd.xingchi.li/reference/show.html","id":null,"dir":"Reference","previous_headings":"","what":"Show the available methods for a fastcpd object — show.fastcpd","title":"Show the available methods for a fastcpd object — show.fastcpd","text":"Show available methods fastcpd object","code":""},{"path":"https://fastcpd.xingchi.li/reference/show.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show the available methods for a fastcpd object — show.fastcpd","text":"","code":"# S3 method for fastcpd show(object)  # S4 method for fastcpd show(object)"},{"path":"https://fastcpd.xingchi.li/reference/show.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show the available methods for a fastcpd object — show.fastcpd","text":"object fastcpd object.","code":""},{"path":"https://fastcpd.xingchi.li/reference/show.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Show the available methods for a fastcpd object — show.fastcpd","text":"return value, called showing list available methods   fastcpd object.","code":""},{"path":"https://fastcpd.xingchi.li/reference/summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Show the summary of a fastcpd object — summary.fastcpd","title":"Show the summary of a fastcpd object — summary.fastcpd","text":"Show summary fastcpd object","code":""},{"path":"https://fastcpd.xingchi.li/reference/summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show the summary of a fastcpd object — summary.fastcpd","text":"","code":"# S3 method for fastcpd summary(object, ...)  # S4 method for fastcpd summary(object, ...)"},{"path":"https://fastcpd.xingchi.li/reference/summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show the summary of a fastcpd object — summary.fastcpd","text":"object fastcpd object. ... Ignored.","code":""},{"path":"https://fastcpd.xingchi.li/reference/summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Show the summary of a fastcpd object — summary.fastcpd","text":"Return (temporarily) invisible copy fastcpd object.   Called primarily printing summary model including   call, change points, cost values estimated parameters.","code":""},{"path":"https://fastcpd.xingchi.li/news/index.html","id":"fastcpd-083","dir":"Changelog","previous_headings":"","what":"fastcpd 0.8.3","title":"fastcpd 0.8.3","text":"Add fastcpd.ts / fastcpd_ts time series data. Fix pre segmengation bug lasso. Fix bug related vanilla_percentage parameter lasso. Add tests invalid family fastcpd.ts. Remove cp_only = TRUE default family “custom”. Improved plotting “ar” “var” families. Add test coverage cp_only = TRUE fastcpd_ts.","code":""},{"path":"https://fastcpd.xingchi.li/news/index.html","id":"fastcpd-082","dir":"Changelog","previous_headings":"","what":"fastcpd 0.8.2","title":"fastcpd 0.8.2","text":"Add cheatsheets WIP. Add smaller examples test penalized linear regression.","code":""},{"path":"https://fastcpd.xingchi.li/news/index.html","id":"fastcpd-081","dir":"Changelog","previous_headings":"","what":"fastcpd 0.8.1","title":"fastcpd 0.8.1","text":"Add new “ar” family autoregressive models. Add new “var” family vector autoregressive models.","code":""},{"path":"https://fastcpd.xingchi.li/news/index.html","id":"fastcpd-080","dir":"Changelog","previous_headings":"","what":"fastcpd 0.8.0","title":"fastcpd 0.8.0","text":"Deal following TODO: Separate use internal C++ cost functions user-defined R cost functions. Add Codecov Icicle plot README. Remove cost_optim cost_update RcppExports.R. Estimate variance “gaussian” family dynamically.","code":"Due to the excessive calls to `glmnet` between R and C++, it is better to use the R implementation of `fastcpd` for lasso."},{"path":"https://fastcpd.xingchi.li/news/index.html","id":"fastcpd-076","dir":"Changelog","previous_headings":"","what":"fastcpd 0.7.6","title":"fastcpd 0.7.6","text":"Move default cost functions definition inside fastcpd definition. Define constant unordered set store family sets. Avoid using length(formals(cost)) check number arguments cost function. Introduce internal family “vanilla”.","code":""},{"path":"https://fastcpd.xingchi.li/news/index.html","id":"fastcpd-075","dir":"Changelog","previous_headings":"","what":"fastcpd 0.7.5","title":"fastcpd 0.7.5","text":"Add variance estimation example linear regression. Update reference page. Add validation family. Add user selection ggplot2 installed. Add AR(1) using forecast example tests.","code":""},{"path":"https://fastcpd.xingchi.li/news/index.html","id":"fastcpd-074","dir":"Changelog","previous_headings":"","what":"fastcpd 0.7.4","title":"fastcpd 0.7.4","text":"Update website UI. Update fastcpd documentation.","code":""},{"path":"https://fastcpd.xingchi.li/news/index.html","id":"fastcpd-073","dir":"Changelog","previous_headings":"","what":"fastcpd 0.7.3","title":"fastcpd 0.7.3","text":"Allow multiple response variables formula. Add fastcpd logo README.","code":""},{"path":"https://fastcpd.xingchi.li/news/index.html","id":"fastcpd-072","dir":"Changelog","previous_headings":"","what":"fastcpd 0.7.2","title":"fastcpd 0.7.2","text":"CRAN release: 2023-09-23 Add suggested package checking tests. Try solve amazing clang-ASAN error CRAN:","code":"Error in dyn.load(file, DLLpath = DLLpath, ...) :   unable to load shared object '/data/gannet/ripley/R/test-clang/mvtnorm/libs/mvtnorm.so':   /data/gannet/ripley/R/test-clang/mvtnorm/libs/mvtnorm.so: undefined symbol: _ZNK7Fortran7runtime10Terminator5CrashEPKcz Calls: <Anonymous> ... asNamespace -> loadNamespace -> library.dynam -> dyn.load"},{"path":"https://fastcpd.xingchi.li/news/index.html","id":"fastcpd-071","dir":"Changelog","previous_headings":"","what":"fastcpd 0.7.1","title":"fastcpd 0.7.1","text":"Add package citation.","code":""},{"path":"https://fastcpd.xingchi.li/news/index.html","id":"fastcpd-070","dir":"Changelog","previous_headings":"","what":"fastcpd 0.7.0","title":"fastcpd 0.7.0","text":"CRAN release: 2023-09-21 Remove C++ unit tests using catch commented code since new version development version Rcpp yet available CRAN. Related pull request: https://github.com/RcppCore/Rcpp/pull/1274. Add documentation fastcpd method.","code":""},{"path":"https://fastcpd.xingchi.li/news/index.html","id":"fastcpd-065","dir":"Changelog","previous_headings":"","what":"fastcpd 0.6.5","title":"fastcpd 0.6.5","text":"Add experiments.","code":""},{"path":"https://fastcpd.xingchi.li/news/index.html","id":"fastcpd-064","dir":"Changelog","previous_headings":"","what":"fastcpd 0.6.4","title":"fastcpd 0.6.4","text":"Check warning messages tests. encapsulation FastcpdParameters members.","code":""},{"path":"https://fastcpd.xingchi.li/news/index.html","id":"fastcpd-063","dir":"Changelog","previous_headings":"","what":"fastcpd 0.6.3","title":"fastcpd 0.6.3","text":"Add CRAN release badge.","code":""},{"path":"https://fastcpd.xingchi.li/news/index.html","id":"fastcpd-062","dir":"Changelog","previous_headings":"","what":"fastcpd 0.6.2","title":"fastcpd 0.6.2","text":"CRAN release: 2023-09-14 Address CRAN comments. Add experiments.","code":""},{"path":"https://fastcpd.xingchi.li/news/index.html","id":"fastcpd-061","dir":"Changelog","previous_headings":"","what":"fastcpd 0.6.1","title":"fastcpd 0.6.1","text":"Address CRAN comments.","code":""},{"path":"https://fastcpd.xingchi.li/news/index.html","id":"fastcpd-060","dir":"Changelog","previous_headings":"","what":"fastcpd 0.6.0","title":"fastcpd 0.6.0","text":"Submit CRAN release.","code":""},{"path":"https://fastcpd.xingchi.li/news/index.html","id":"fastcpd-057","dir":"Changelog","previous_headings":"","what":"fastcpd 0.5.7","title":"fastcpd 0.5.7","text":"Fix loss function custom mean variance change.","code":""},{"path":"https://fastcpd.xingchi.li/news/index.html","id":"fastcpd-056","dir":"Changelog","previous_headings":"","what":"fastcpd 0.5.6","title":"fastcpd 0.5.6","text":"Add stargazers README.","code":""},{"path":"https://fastcpd.xingchi.li/news/index.html","id":"fastcpd-055","dir":"Changelog","previous_headings":"","what":"fastcpd 0.5.5","title":"fastcpd 0.5.5","text":"Add example test multivariate mean shift. Add example test multivariate variance change. Add example test multivariate mean variance change. Add test linear regression multi-dimensional responses.","code":""},{"path":"https://fastcpd.xingchi.li/news/index.html","id":"fastcpd-054","dir":"Changelog","previous_headings":"","what":"fastcpd 0.5.4","title":"fastcpd 0.5.4","text":"Fix bug change point detected.","code":""},{"path":"https://fastcpd.xingchi.li/news/index.html","id":"fastcpd-053","dir":"Changelog","previous_headings":"","what":"fastcpd 0.5.3","title":"fastcpd 0.5.3","text":"Add experiments commented sake test time without affecting test coverage. Add examples README. Add CRAN manual using R CMD Rd2pdf . --output=man/figures/manual.pdf --force ---preview stackoverflow. Add example multiple epochs using custom cost functions. Add table contents README.","code":""},{"path":"https://fastcpd.xingchi.li/news/index.html","id":"fastcpd-052","dir":"Changelog","previous_headings":"","what":"fastcpd 0.5.2","title":"fastcpd 0.5.2","text":"Add one-dimensional linear regression example plot.","code":""},{"path":"https://fastcpd.xingchi.li/news/index.html","id":"fastcpd-051","dir":"Changelog","previous_headings":"","what":"fastcpd 0.5.1","title":"fastcpd 0.5.1","text":"Prepare CRAN release.","code":""},{"path":"https://fastcpd.xingchi.li/news/index.html","id":"fastcpd-050","dir":"Changelog","previous_headings":"","what":"fastcpd 0.5.0","title":"fastcpd 0.5.0","text":"Rewrite whole package C++ except LASSO due excessive calls R C++ glmnet.","code":""},{"path":"https://fastcpd.xingchi.li/news/index.html","id":"fastcpd-040","dir":"Changelog","previous_headings":"","what":"fastcpd 0.4.0","title":"fastcpd 0.4.0","text":"Add transition vanilla PELT SeN using vanilla_percentage parameter.","code":""},{"path":"https://fastcpd.xingchi.li/news/index.html","id":"fastcpd-033","dir":"Changelog","previous_headings":"","what":"fastcpd 0.3.3","title":"fastcpd 0.3.3","text":"Merge implementation vanilla PELT SeN. Encapsulate implementation binding new coefficients previous coefficients. Rewrite fastcpd parameters updating C++.","code":""},{"path":"https://fastcpd.xingchi.li/news/index.html","id":"fastcpd-032","dir":"Changelog","previous_headings":"","what":"fastcpd 0.3.2","title":"fastcpd 0.3.2","text":"Integrate initialization update theta_hat, theta_sum hessian. Combine theta estimation single function. Add parameter vanilla_percentage denote method switching vanilla PETL SeN. Add documentation cp_only parameter. Add preparation merging vanilla PELT SeN.","code":""},{"path":"https://fastcpd.xingchi.li/news/index.html","id":"fastcpd-031","dir":"Changelog","previous_headings":"","what":"fastcpd 0.3.1","title":"fastcpd 0.3.1","text":"Add examples tests fastcpd. Rearrange C++ functions. Add precondition check.","code":""},{"path":"https://fastcpd.xingchi.li/news/index.html","id":"fastcpd-030","dir":"Changelog","previous_headings":"","what":"fastcpd 0.3.0","title":"fastcpd 0.3.0","text":"Bump test coverage class methods fastcpd.","code":""},{"path":"https://fastcpd.xingchi.li/news/index.html","id":"fastcpd-029","dir":"Changelog","previous_headings":"","what":"fastcpd 0.2.9","title":"fastcpd 0.2.9","text":"Fix Poisson regression bug related lfactorial.","code":""},{"path":"https://fastcpd.xingchi.li/news/index.html","id":"fastcpd-028","dir":"Changelog","previous_headings":"","what":"fastcpd 0.2.8","title":"fastcpd 0.2.8","text":"Make penalized linear regression estimated coefficients output sparse.","code":""},{"path":"https://fastcpd.xingchi.li/news/index.html","id":"fastcpd-027","dir":"Changelog","previous_headings":"","what":"fastcpd 0.2.7","title":"fastcpd 0.2.7","text":"Fix mean change example bug. Update documentation redirect README pkgdown generated webpage. Add contact methods ways file ticket.","code":""},{"path":"https://fastcpd.xingchi.li/news/index.html","id":"fastcpd-026","dir":"Changelog","previous_headings":"","what":"fastcpd 0.2.6","title":"fastcpd 0.2.6","text":"Add C++ sanity check Logistic regression data, .e. binomial family. Add examples tests fastcpd. Rename C++ source files follow Unix convention. Update documentation link README.","code":""},{"path":"https://fastcpd.xingchi.li/news/index.html","id":"fastcpd-025","dir":"Changelog","previous_headings":"","what":"fastcpd 0.2.5","title":"fastcpd 0.2.5","text":"Hide internal functions documentation. Export fastcpd class.","code":""},{"path":"https://fastcpd.xingchi.li/news/index.html","id":"fastcpd-024","dir":"Changelog","previous_headings":"","what":"fastcpd 0.2.4","title":"fastcpd 0.2.4","text":"Add column name thetas slot fastcpd class. Fix plot residuals responses appear plot. Default cp_only FALSE. Remove residuals summary method.","code":""},{"path":"https://fastcpd.xingchi.li/news/index.html","id":"fastcpd-023","dir":"Changelog","previous_headings":"","what":"fastcpd 0.2.3","title":"fastcpd 0.2.3","text":"Add missing examples linear regression LASSO.","code":""},{"path":"https://fastcpd.xingchi.li/news/index.html","id":"fastcpd-022","dir":"Changelog","previous_headings":"","what":"fastcpd 0.2.2","title":"fastcpd 0.2.2","text":"Add examples illustrate use fastcpd function. Indicating internal functions users use .","code":""},{"path":"https://fastcpd.xingchi.li/news/index.html","id":"fastcpd-021","dir":"Changelog","previous_headings":"","what":"fastcpd 0.2.1","title":"fastcpd 0.2.1","text":"Add examples README.","code":""},{"path":"https://fastcpd.xingchi.li/news/index.html","id":"fastcpd-020","dir":"Changelog","previous_headings":"","what":"fastcpd 0.2.0","title":"fastcpd 0.2.0","text":"Added NEWS.md file track changes package.","code":""}]
